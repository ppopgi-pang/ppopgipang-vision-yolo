{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3j70MunHa_AO",
      "metadata": {
        "id": "3j70MunHa_AO"
      },
      "source": [
        "# ppopgipang-vision-yolo í•™ìŠµ ë…¸íŠ¸ë¶\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ì•„ë˜ì²˜ëŸ¼ êµ¬ì„±ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ YOLOv8ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "data_root/\n",
        "  bboxes.json\n",
        "  classes.txt\n",
        "  images/\n",
        "  labels/\n",
        "\n",
        "ê°€ì •:\n",
        "- labels/ ì— YOLO í¬ë§· ë¼ë²¨ì´ ìˆìŠµë‹ˆë‹¤ (class x_center y_center width height, ì •ê·œí™”).\n",
        "- labels/ ê°€ ë¹„ì–´ ìˆê³  bboxes.json ì´ COCO í˜•ì‹ì´ë©´ ë³€í™˜ ì…€ë¡œ ë¼ë²¨ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë°ì´í„° ê²½ë¡œê°€ ë‹¤ë¥´ë©´ ì•„ë˜ DATA_ROOT ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f_Da0Xopa_AP",
      "metadata": {
        "id": "f_Da0Xopa_AP"
      },
      "outputs": [],
      "source": [
        "!pip install -U ultralytics\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b242ffc",
      "metadata": {},
      "source": [
        "## êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pxKRSDr7gqZt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxKRSDr7gqZt",
        "outputId": "a51b156d-62f7-4b52-b17a-e149986b618c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b700f227",
      "metadata": {},
      "source": [
        "## íŒŒì¼ í™•ì¸ ë° DATA_ROOT ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4YlH3lvCa_AP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YlH3lvCa_AP",
        "outputId": "c1b00c8a-094d-493b-96d1-439e40201e86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA_ROOT: /content\n",
            "images ì¡´ì¬ ì—¬ë¶€: True labels ì¡´ì¬ ì—¬ë¶€: True\n"
          ]
        }
      ],
      "source": [
        "DATA_ROOT = Path(\"/content\").resolve()  # notebooks/ ê¸°ì¤€ repo ë£¨íŠ¸\n",
        "BBOXES_JSON = DATA_ROOT /\"bboxes.json\"\n",
        "CLASSES_TXT = DATA_ROOT /\"classes.txt\"\n",
        "IMAGES_DIR = DATA_ROOT / \"images\"\n",
        "LABELS_DIR = DATA_ROOT / \"labels\"\n",
        "\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"images ì¡´ì¬ ì—¬ë¶€:\", IMAGES_DIR.exists(), \"labels ì¡´ì¬ ì—¬ë¶€:\", LABELS_DIR.exists())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a29e7fe",
      "metadata": {},
      "source": [
        "## ì¶œë ¥ ê²°ê³¼ ê²½ë¡œ ì§€ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q5s4YIU84OiR",
      "metadata": {
        "id": "q5s4YIU84OiR"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# Colab ìª½ ê²°ê³¼ ê²½ë¡œ\n",
        "RUNS_DIR = Path(DATA_ROOT) / \"runs\"\n",
        "\n",
        "# Drive ìª½ ì €ì¥ ê²½ë¡œ (ì›í•˜ëŠ” ìœ„ì¹˜ë¡œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "DRIVE_OUT = Path(\"/content/drive/MyDrive/yolo_results/yolov8_train\")\n",
        "\n",
        "DRIVE_OUT.parent.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36f8487d",
      "metadata": {},
      "source": [
        "## Unknown í´ë˜ìŠ¤ ì œê±°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AAOoA6usDd7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAOoA6usDd7e",
        "outputId": "8b43ac42-b2f3-4b01-c8eb-f98b990044ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… unknown í´ë˜ìŠ¤ ì œê±° ì™„ë£Œ\n",
            "ğŸ—‘ï¸ ì œê±°ëœ ë°•ìŠ¤ ìˆ˜: 2774\n",
            "ğŸ“„ ì˜í–¥ì„ ë°›ì€ label íŒŒì¼ ìˆ˜: 1978\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "LABEL_DIR = Path(\"/content/labels\")\n",
        "UNKNOWN_CLASS_ID = 10  # unknown í´ë˜ìŠ¤ id\n",
        "\n",
        "removed_boxes = 0\n",
        "affected_files = 0\n",
        "\n",
        "for label_file in LABEL_DIR.glob(\"*.txt\"):\n",
        "    with open(label_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    new_lines = []\n",
        "    file_removed = 0\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if not parts:\n",
        "            continue\n",
        "\n",
        "        class_id = int(parts[0])\n",
        "        if class_id == UNKNOWN_CLASS_ID:\n",
        "            file_removed += 1\n",
        "            removed_boxes += 1\n",
        "        else:\n",
        "            new_lines.append(line)\n",
        "\n",
        "    if file_removed > 0:\n",
        "        affected_files += 1\n",
        "        with open(label_file, \"w\") as f:\n",
        "            f.writelines(new_lines)\n",
        "\n",
        "print(\"âœ… unknown í´ë˜ìŠ¤ ì œê±° ì™„ë£Œ\")\n",
        "print(f\"ğŸ—‘ï¸ ì œê±°ëœ ë°•ìŠ¤ ìˆ˜: {removed_boxes}\")\n",
        "print(f\"ğŸ“„ ì˜í–¥ì„ ë°›ì€ label íŒŒì¼ ìˆ˜: {affected_files}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7d0a3f",
      "metadata": {},
      "source": [
        "## í´ë˜ìŠ¤ ëª©ë¡ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8OcJRb_8a_AP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OcJRb_8a_AP",
        "outputId": "8f8efaed-32f6-4d25-ee7b-22b0772ee705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í´ë˜ìŠ¤ ëª©ë¡: ['Chiikawa', 'Hello Kitty', 'Kuromi', 'Mickey Mouse', 'Minions', 'Pikachu', 'Shin-chan', 'Snoopy', 'Stitch', 'Totoro']\n"
          ]
        }
      ],
      "source": [
        "if CLASSES_TXT.exists():\n",
        "    class_names = [line.strip() for line in CLASSES_TXT.read_text().splitlines() if line.strip()]\n",
        "else:\n",
        "    class_names = []\n",
        "\n",
        "print(\"í´ë˜ìŠ¤ ëª©ë¡:\", class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QcSunafda_AP",
      "metadata": {
        "id": "QcSunafda_AP"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "label_files = list(LABELS_DIR.rglob(\"*.txt\")) if LABELS_DIR.exists() else []\n",
        "if label_files:\n",
        "    print(f\"ë¼ë²¨ íŒŒì¼ì´ {len(label_files)}ê°œ ìˆì–´ ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "else:\n",
        "    if not BBOXES_JSON.exists():\n",
        "        print(\"labels/ ê°€ ë¹„ì–´ ìˆê³  bboxes.json ë„ ì—†ìŠµë‹ˆë‹¤. ë¼ë²¨ì„ ì œê³µí•˜ê±°ë‚˜ ì´ ì…€ì„ ìˆ˜ì •í•˜ì„¸ìš”.\")\n",
        "    else:\n",
        "        data = json.loads(BBOXES_JSON.read_text())\n",
        "        is_coco = isinstance(data, dict) and all(k in data for k in (\"images\", \"annotations\", \"categories\"))\n",
        "        if not is_coco:\n",
        "            raise ValueError(\"bboxes.json ì´ COCO í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì´ ì…€ì„ ìˆ˜ì •í•˜ì„¸ìš”.\")\n",
        "\n",
        "        coco_categories = {c[\"id\"]: c[\"name\"] for c in data[\"categories\"]}\n",
        "        if not class_names:\n",
        "            class_names = [coco_categories[k] for k in sorted(coco_categories)]\n",
        "            CLASSES_TXT.write_text(\"\\n\".join(class_names))\n",
        "            print(\"COCO ì¹´í…Œê³ ë¦¬ë¡œ classes.txt ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "        name_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "        missing = [n for n in coco_categories.values() if n not in name_to_idx]\n",
        "        if missing:\n",
        "            print(\"ê²½ê³ : classes.txt ì— ì—†ëŠ” ì¹´í…Œê³ ë¦¬:\", missing)\n",
        "\n",
        "        image_info = {img[\"id\"]: img for img in data[\"images\"]}\n",
        "        ann_by_image = defaultdict(list)\n",
        "        for ann in data[\"annotations\"]:\n",
        "            if ann.get(\"iscrowd\"):\n",
        "                continue\n",
        "            ann_by_image[ann[\"image_id\"]].append(ann)\n",
        "\n",
        "        LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        for img_id, info in image_info.items():\n",
        "            file_name = info.get(\"file_name\")\n",
        "            if not isinstance(file_name, str):\n",
        "                continue\n",
        "            img_rel = Path(file_name)\n",
        "            if img_rel.parts and img_rel.parts[0] == \"images\":\n",
        "                img_rel = Path(*img_rel.parts[1:])\n",
        "\n",
        "            width = info.get(\"width\")\n",
        "            height = info.get(\"height\")\n",
        "            if not width or not height:\n",
        "                continue\n",
        "\n",
        "            lines = []\n",
        "            for ann in ann_by_image.get(img_id, []):\n",
        "                bbox = ann.get(\"bbox\")\n",
        "                if not bbox or len(bbox) != 4:\n",
        "                    continue\n",
        "                x, y, w, h = bbox\n",
        "                if w <= 0 or h <= 0:\n",
        "                    continue\n",
        "\n",
        "                x_c = (x + w / 2) / width\n",
        "                y_c = (y + h / 2) / height\n",
        "                w_n = w / width\n",
        "                h_n = h / height\n",
        "\n",
        "                cat_name = coco_categories.get(ann.get(\"category_id\"))\n",
        "                if cat_name not in name_to_idx:\n",
        "                    continue\n",
        "                cls_id = name_to_idx[cat_name]\n",
        "\n",
        "                lines.append(f\"{cls_id} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\")\n",
        "\n",
        "            label_path = LABELS_DIR / img_rel.with_suffix(\".txt\")\n",
        "            label_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            label_path.write_text(\"\\n\".join(lines))\n",
        "\n",
        "        print(\"labels/ ì— YOLO ë¼ë²¨ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤:\", LABELS_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Clm1UUbra_AP",
      "metadata": {
        "id": "Clm1UUbra_AP"
      },
      "source": [
        "## í•™ìŠµ/ê²€ì¦ ë¶„í•  ë° data.yaml ìƒì„±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dZtyzWwXa_AQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZtyzWwXa_AQ",
        "outputId": "13f36228-68ad-4a8d-e861-d85b05456880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train ê²½ë¡œ: /content/train.txt\n",
            "val ê²½ë¡œ: /content/val.txt\n"
          ]
        }
      ],
      "source": [
        "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "train_dir = IMAGES_DIR / \"train\"\n",
        "val_dir = IMAGES_DIR / \"val\"\n",
        "train_txt = DATA_ROOT / \"train.txt\"\n",
        "val_txt = DATA_ROOT / \"val.txt\"\n",
        "\n",
        "if train_dir.exists() and val_dir.exists():\n",
        "    train_spec = train_dir.resolve().as_posix()\n",
        "    val_spec = val_dir.resolve().as_posix()\n",
        "elif train_txt.exists() and val_txt.exists():\n",
        "    train_spec = train_txt.resolve().as_posix()\n",
        "    val_spec = val_txt.resolve().as_posix()\n",
        "else:\n",
        "    image_paths = [p for p in IMAGES_DIR.rglob(\"*\") if p.suffix.lower() in IMAGE_EXTS]\n",
        "    image_paths = sorted(image_paths)\n",
        "    if not image_paths:\n",
        "        raise FileNotFoundError(f\"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {IMAGES_DIR}\")\n",
        "\n",
        "    random.seed(42)\n",
        "    random.shuffle(image_paths)\n",
        "    split = int(len(image_paths) * 0.8)\n",
        "    train_paths = image_paths[:split]\n",
        "    val_paths = image_paths[split:]\n",
        "\n",
        "    train_txt.write_text(\"\\n\".join(p.resolve().as_posix() for p in train_paths))\n",
        "    val_txt.write_text(\"\\n\".join(p.resolve().as_posix() for p in val_paths))\n",
        "\n",
        "    train_spec = train_txt.resolve().as_posix()\n",
        "    val_spec = val_txt.resolve().as_posix()\n",
        "\n",
        "print(\"train ê²½ë¡œ:\", train_spec)\n",
        "print(\"val ê²½ë¡œ:\", val_spec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DbxT03fqa_AQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbxT03fqa_AQ",
        "outputId": "9dc570a5-fd90-44e6-b2a5-ce03a87bb9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path: /content\n",
            "train: /content/train.txt\n",
            "val: /content/val.txt\n",
            "nc: 10\n",
            "names: [\"Chiikawa\", \"Hello Kitty\", \"Kuromi\", \"Mickey Mouse\", \"Minions\", \"Pikachu\", \"Shin-chan\", \"Snoopy\", \"Stitch\", \"Totoro\"]\n"
          ]
        }
      ],
      "source": [
        "DATA_YAML = DATA_ROOT / \"data.yaml\"\n",
        "names_yaml = json.dumps(class_names)\n",
        "data_yaml_text = \"\\n\".join([\n",
        "    f\"path: {DATA_ROOT.as_posix()}\",\n",
        "    f\"train: {train_spec}\",\n",
        "    f\"val: {val_spec}\",\n",
        "    f\"nc: {len(class_names)}\",\n",
        "    f\"names: {names_yaml}\",\n",
        "])\n",
        "DATA_YAML.write_text(data_yaml_text)\n",
        "print(DATA_YAML.read_text())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8RlJJCuPa_AQ",
      "metadata": {
        "id": "8RlJJCuPa_AQ"
      },
      "source": [
        "## YOLOv8 í•™ìŠµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WawlxDiJa_AQ",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WawlxDiJa_AQ",
        "outputId": "dde67bcc-df30-4a0f-9025-a26f3b82aa01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.248 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.247 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=30, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_768_aug2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/yolov8n_768_aug2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n",
            "Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 914.3Â±772.0 MB/s, size: 22.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/labels... 4014 images, 16166 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 19072/19072 2.1Kit/s 8.9s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 334.9Â±259.7 MB/s, size: 21.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/labels... 982 images, 4047 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4769/4769 1.3Kit/s 3.8s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/labels.cache\n",
            "Plotting labels to /content/runs/yolov8n_768_aug2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 768 train, 768 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/yolov8n_768_aug2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      9.82G      1.449        6.5      2.007          8        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1192/1192 1.4it/s 14:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 150/150 2.2it/s 1:08\n",
            "                   all       4769        964      0.238      0.267      0.146     0.0772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      9.74G      1.468      3.361      2.022         12        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1192/1192 1.4it/s 14:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 150/150 2.2it/s 1:08\n",
            "                   all       4769        964      0.275      0.106     0.0519     0.0197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      9.52G      1.672      3.873      2.227          8        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1192/1192 1.4it/s 13:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 150/150 2.2it/s 1:08\n",
            "                   all       4769        964      0.564     0.0516     0.0267    0.00944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      9.52G      1.781      4.238      2.352         14        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1192/1192 1.4it/s 13:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 150/150 2.2it/s 1:08\n",
            "                   all       4769        964      0.565       0.11     0.0499     0.0175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      9.52G      1.665      3.926      2.235          8        768: 91% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 1082/1192 1.4it/s 12:39<1:17"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "results = model.train(\n",
        "    data=\"/content/data.yaml\",\n",
        "    epochs=80,\n",
        "    imgsz=768,\n",
        "    batch=62,                # A100 ê¸°ì¤€ ì‹¤ì‚¬ìš© ë°°ì¹˜\n",
        "    device=0,                # A100\n",
        "    amp=True,                # Automatic Mixed Precision\n",
        "    cache=\"ram\",             # RAM ìºì‹œ (ì†ë„ ìš°ì„ )\n",
        "    # Optimizer (auto â†’ SGD ì„ íƒë¨)\n",
        "    optimizer=\"auto\",\n",
        "    lr0=0.01,\n",
        "    momentum=0.9,\n",
        "    weight_decay=5e-4,\n",
        "    # Data Augmentation (bbox ìœ ì§€)\n",
        "    degrees=15,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    shear=1.0,\n",
        "    fliplr=0.5,\n",
        "    mosaic=0.3,\n",
        "    close_mosaic=10,\n",
        "    # Color Augmentation\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    # Warmup\n",
        "    warmup_epochs=3,\n",
        "    warmup_bias_lr=0.1,\n",
        "    warmup_momentum=0.8,\n",
        "    # Training setup\n",
        "    workers=8,\n",
        "    val=True,\n",
        "    patience=100,\n",
        "    pretrained=True,\n",
        "    # Output\n",
        "    project=str(RUNS_DIR),\n",
        "    name=\"yolov8m_768_augA100\",\n",
        ")\n",
        "\n",
        "if DRIVE_OUT.exists():\n",
        "    shutil.rmtree(DRIVE_OUT)\n",
        "\n",
        "shutil.copytree(RUNS_DIR, DRIVE_OUT)\n",
        "\n",
        "print(\"âœ… í•™ìŠµ ê²°ê³¼ Google Driveë¡œ ë³µì‚¬ ì™„ë£Œ\")\n",
        "print(\"ğŸ“ ìœ„ì¹˜:\", DRIVE_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5SdIfSo4Q6Y",
      "metadata": {
        "id": "f5SdIfSo4Q6Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "LOysyDDqa_AQ",
      "metadata": {
        "id": "LOysyDDqa_AQ"
      },
      "source": [
        "## ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶”ë¡ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaO8MVM4a_AQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eaO8MVM4a_AQ",
        "outputId": "9855681f-37c6-4cbb-c21d-e22d922ec6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/yolo/images/train/32239b0c-9dd2-4e17-a4b2-3defcefa2f4c.jpg: 640x480 4 unknowns, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/content/runs/detect/predict\u001b[0m\n",
            "ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: /content/runs/detect/predict\n"
          ]
        }
      ],
      "source": [
        "sample_images = [p for p in IMAGES_DIR.rglob(\"*\") if p.suffix.lower() in IMAGE_EXTS]\n",
        "if sample_images:\n",
        "    pred = model.predict(source=str(sample_images[0]), conf=0.25, save=True)\n",
        "    print(\"ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜:\", pred[0].save_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ny7bOqX00r-O",
      "metadata": {
        "id": "ny7bOqX00r-O"
      },
      "source": [
        "## í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FmTEXFVT0qxY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmTEXFVT0qxY",
        "outputId": "42e7141e-f3f9-4e0d-f2eb-0d90254ced72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì´ í´ë˜ìŠ¤ ë“±ì¥ ìˆ˜: 10\n",
            "top10: [(9, 603), (1, 543), (7, 515), (6, 387), (0, 369), (5, 339), (4, 270), (2, 258), (3, 242), (8, 203)]\n",
            "í´ë˜ìŠ¤ë‹¹ ì¤‘ì•™ê°’ ë°•ìŠ¤ ìˆ˜: 369\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# DATA_ROOT, LABELS_DIR, IMAGES_DIR, train_pathsëŠ” ì´ì „ ì…€ì—ì„œ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "# ì´ ì…€ì—ì„œëŠ” í•´ë‹¹ ë³€ìˆ˜ë“¤ì„ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "cnt = Counter()\n",
        "\n",
        "# í›ˆë ¨ ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡(train_paths)ì„ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ë¼ë²¨ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
        "for image_path in train_paths:\n",
        "    # ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ë¼ë²¨ íŒŒì¼ ê²½ë¡œë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "    # ì˜ˆ: /content/images/subdir/img.jpg -> /content/labels/subdir/img.txt\n",
        "    relative_path_to_image = image_path.relative_to(IMAGES_DIR)\n",
        "    label_path = LABELS_DIR / relative_path_to_image.with_suffix(\".txt\")\n",
        "\n",
        "    if label_path.exists():\n",
        "        for line in label_path.read_text().splitlines():\n",
        "            if line.strip():\n",
        "                # YOLO í¬ë§·: <class_id> <x_center> <y_center> <width> <height>\n",
        "                parts = line.split()\n",
        "                if len(parts) > 0:\n",
        "                    try:\n",
        "                        cls = int(parts[0]) # ì²« ë²ˆì§¸ ìš”ì†Œê°€ í´ë˜ìŠ¤ IDì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
        "                        cnt[cls] += 1\n",
        "                    except ValueError:\n",
        "                        print(f\"ê²½ê³ : {label_path} íŒŒì¼ì˜ '{line}' ë¼ì¸ì—ì„œ í´ë˜ìŠ¤ IDë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
        "                else:\n",
        "                    print(f\"ê²½ê³ : {label_path} íŒŒì¼ì— ë¹ˆ ë¼ì¸ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ ë¼ì¸ì´ ìˆìŠµë‹ˆë‹¤: '{line}'. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
        "    # else:\n",
        "    #     print(f\"ê²½ê³ : {label_path} ë¼ë²¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ì´ë¯¸ì§€ì˜ ë¼ë²¨ì€ ì§‘ê³„ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"ì´ í´ë˜ìŠ¤ ë“±ì¥ ìˆ˜:\", len(cnt))\n",
        "print(\"top10:\", cnt.most_common(20))\n",
        "\n",
        "if len(cnt) > 0:\n",
        "    # í´ë˜ìŠ¤ê°€ ì§‘ê³„ë˜ì—ˆì„ ë•Œë§Œ ì¤‘ì•™ê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "    print(\"í´ë˜ìŠ¤ë‹¹ ì¤‘ì•™ê°’ ë°•ìŠ¤ ìˆ˜:\", sorted(cnt.values())[len(cnt)//2])\n",
        "else:\n",
        "    print(\"ê²½ê³ : ë¼ë²¨ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
